INTRO
	Continuous Integration is a software development practice in which developers are required to frequently commit changes to the source code in a shared repository. Each commit is then continuously pulled & built. 
	Jenkins is an open source, Continuous Integration (CI) tool. It continuously pulls, builds and tests any code commits made by a developer with the help of plugins.
	Slave/Agent - It is typically a machine, or container, which connects to a Jenkins master and executes tasks when directed by the master.
	Executor - A slot for execution of work defined by Project/Job. A Node may have zero or more Executors configured which corresponds to how many concurrent Projects or Pipelines are able to execute on that Node.
	Label - User-defined text for grouping Agents, typically by similar functionality or capability. For example linux for Linux-based agents or docker for Docker-capable agents.
	Workspace/directory - It is specific to a Job. It is where work can be done on files checked out from source control. Jenkins uses the name of the Pipeline to create directories on disk. Pipeline names which include spaces may uncover bugs in scripts which do not expect paths to contain spaces.
	Schedule a build periodically - 
		Syntax: (Minute Hour DayOfMonth(1-31) Month(1-12) DayOfWeek(0-7, where 0 and 7 are Sunday))
		Example: H/2 * * * * (schedule your build for every 2 minutes)
	Build
		<build.url>/stop - aborts a Pipeline.
		<build.url>/term - forcibly terminates a build (should only be used if stop does not work.
		<build.url>/kill - hard kill a pipeline. This is the most destructive way to stop a pipeline and should only be used as a last resort.
	Server
		Using BASH - $ sudo service jenkins restart/stop/start
		<jenkins.server.url>/restart
		<jenkins.server.url>/safeRestart - Puts Jenkins into the quiet mode, wait for existing builds to be completed, and then restart Jenkins
		<jenkins.server.url>/exit
		<jenkins.server.url>/safeExit - Puts Jenkins into the quiet mode, wait for existing builds to be completed, and then shut down Jenkins
		<jenkins.server.url>/quietDown - Puts Jenkins in a Quiet mode, in preparation for a restart. In that mode Jenkins don’t start any build
		<jenkins.server.url>/cancelQuietDown - Cancel the effect of the “quiet-down” command
INSTALLATION (on ubuntu)
	Step 1: Install Java
		$ sudo apt update
		$ sudo apt install openjdk-8-jdk
	Step 2: Download Jenkins Repository and add it to the system
		$ wget -q -O - https://pkg.jenkins.io/debian/jenkins.io.key | sudo apt-key add –
		$ sudo sh -c 'echo deb http://pkg.jenkins.io/debian-stable binary/ > /etc/apt/sources.list.d/jenkins.list'
	Step 3: Install Jenkins
		$ sudo apt update
		$ sudo apt install Jenkins
	Step 4: Once Jenkins is up and running, access it from the link:
		http://localhost:8080
	If your /etc/init.d/jenkins file fails to start Jenkins, edit the $JENKINS_HOME/config.xml to replace the line ----HTTP_PORT=8080---- with ----HTTP_PORT=8081---- Here, "8081" was chosen but you can put another port available.
	Post-installation setup wizard
		Unlocking Jenkins
		Creating the first administrator user
		
MANAGE JENKINS - Jenkins Dashboard -> Manage Jenkins
	Configure System -
		Can be used to manage paths to various tools to use in builds.
		Jenkins dynamically adds the config fields after the plugins are installed.
	Manage Plugins - Plugins can be removed, updated and installed through manage plugin screen.
	System Info -
		List all the current java properties and system environment variables.
		System log - view Jenkins log in real time.
		Script console - lets you run groovy scripts on the server.
		Manage nodes - configure the number of builds you want.
		Shutdown - click prepare to shutdown link to prevent any new builds from being started. After all current builds are finished, Jenkins will shut down cleanly.
	Configure Global Security -
		Ability to have secure config for different users.
		Add the users and go-to ‘manage users’ option to provide permissions
		To set authorizations, and click on matrix-based security
		
PLUGINS - Jenkins Dashboard -> Manage Jenkins -> Manage Plugins
	To uninstall plugins, go-to manage plugins and click on the installed tab and click on uninstall for the plugin. Ensure to restart Jenkins for changes to take effect
	In Case of need to install an older version of the plugin, download from the site and click on Upload option to do it manually.

BUILD PIPELINE
	Build pipeline can be used to chain several jobs together and run them in a sequence
	Before using it, you have to add this plugin
	Example - 
		Step 1: Create 3 freestyle Jobs (Job1, Job2, Job3)
		Step 2: Chain the 3 Jobs together
			Job1 -> configure -> Post Build -> Build other projects -> Job2
			Job2 -> configure -> Post Build -> Build other projects -> Job3
		Step 3: Create a build pipeline view
			Jenkins Dashboard -> Add view -> Enter a name -> Build pipeline view -> ok -> configure -> Pipeline flow -> Select Initial job -> Job1 -> ok
		Step 4: Run the Build Pipeline

DIFFERENT TYPES OF JENKINS JOBS
	Freestyle - Freestyle build jobs are general-purpose build jobs, which provides maximum flexibility. It can be used for any type of project.
	Pipeline - This project runs the entire software development workflow as code. You can code the entire workflow and put it in a Jenkinsfile
	Multiconfiguration - The multiconfiguration project allows you to run the same build job on different environments. It is used for testing an application in different environments.
	
JENKINSFILE	- can only be used when creating pipeline-type job
	The first line of a Jenkinsfile should be #!/usr/bin/env groovy
	It can be written based on two syntaxes -
		Scripted pipeline - Code is written on the Jenkins UI instance and is enclosed within the node block
			node {
				stage('Build') {
					echo 'Building....'
				}
				stage('Test') {
					echo 'Testing....'
				}
				stage('Deploy') {
					echo 'Deploying....'
				}
			}
		Declarative pipeline - Code is written in 'Jenkinsfile' file which can be checked into a project’s source control repository
			pipeline {
				agent any  // The agent directive, which is required, instructs Jenkins to allocate an executor and workspace for the Pipeline.
				stages {
					stage('Build') {
						steps {
							echo 'Building..'
						}
					}
					stage('Test') {
						steps {
							echo 'Testing..'
						}
					}
					stage('Deploy') {
						steps {
							echo 'Deploying....'
						}
					}
				}
			}
	Pipeline - A user defined block which contains all the stages. It is a key part of declarative pipeline syntax.
	Node - A node is a machine that executes an entire workflow. It is a key part of the scripted pipeline syntax.
	Agent - It indicates that Jenkins should allocate an executor and workspace/directory for this part of the Pipeline.
	Stages - It contains all the work; each stage performs a specific task.
	Steps - steps are carried out in sequence to execute a stage
	example -
		node {
			stage(‘SCM checkout’) {
				//Checkout from your SCM(Source Control Management)
				//For eg: Git Checkout
			}
			stage(‘Build’) {
				//Compile code
				//Install dependencies
				//Perform Unit Test, Integration Test
			}
			stage(‘Test’) {
				//Resolve test server dependencies
				//Perform UAT
			}
			stage(‘Deploy’) {
				//Deploy code to prod server
				//Solve dependency issues
			}
		}
	Snippet Generator - localhost:8080/pipeline-syntax
	Global Variable Reference - localhost:8080/pipeline-syntax/globals
		Like the Snippet Generator, it is also dynamically populated by plugins. 
		Unlike the Snippet Generator however, the Global Variable Reference only contains documentation for variables provided by Pipeline or plugins, which are available for Pipelines
	Code snippet
		checkout scm - The checkout step will checkout code from source control; scm is a special variable which instructs the checkout step to clone the specific revision which triggered this Pipeline run
		git url: 'git://example.com/amazing-project.git', branch: 'master' - consider this as a function where 'git' is the function name and 'url' and 'branch' are the named-parameters
		The sh step assumes the system is Unix/Linux-based, for Windows-based systems the bat could be used instead.
		`make check` returns non-zero on test failures
		Pipeline will only continue if a zero exit code is returned by the 'sh' command. Any non-zero exit code will fail the Pipeline. Inline shell conditional (sh 'make || true') ensures that the sh step always sees a zero exit code.
		The "Deploy" stage will only execute assuming previous stages completed successfully, otherwise the Pipeline would have exited early. Accessing the currentBuild.result variable allows the Pipeline to determine if there were any test failures. In which case, the value would be UNSTABLE.
			Declarative Pipeline
				stage('Deploy') {
					when {
						expression {
							currentBuild.result == null || currentBuild.result == 'SUCCESS'
						}
					}
					steps {
						sh 'make publish'
					}
				}
			Script Pipeline
				stage('Deploy') {
					if (currentBuild.result == null || currentBuild.result == 'SUCCESS') {
						sh 'make publish'
					}
				}
				
ADVANCED SYNTAX FOR PIPELINE
	String Interpolation -
		def username = 'Jenkins'
		echo 'Hello Mr. ${username}'  #=> Hello Mr. ${username}
		echo "I said, Hello Mr. ${username}"  #=> I said, Hello Mr. Jenkins
	Working with the Environment - 
		Jenkins Pipeline exposes environment variables via the global variable env, which is available from anywhere within a Jenkinsfile. ex- env.BUILD_ID, env.JOB_NAME, env.JENKINS_URL
		Setting an environment variable within a Jenkins Pipeline for -
			Declarative Pipeline - supports an environment directive. An environment directive used in the top-level pipeline block will apply to all steps within the Pipeline. An environment directive defined within a stage will only apply the given environment variables to steps within the stage
				environment {
					CC = 'clang'
				}
			Script Pipeline - must use the withEnv step
				withEnv(["PATH+MAVEN=${tool 'M3'}/bin"]) {
					sh 'mvn -B verify'
				}
	Parameters - Declarative Pipeline supports parameters out-of-the-box, allowing the Pipeline to accept user specified parameters at runtime via the parameters directive. Configuring parameters with Scripted Pipeline is done with the properties step, which can be found in the Snippet Generator
		Declarative Pipeline
			parameters {
				string(name: 'Greeting', defaultValue: 'Hello', description: 'How should I greet the world?')
			}
			....
			echo "${params.Greeting} World!"
		Script Pipeline
			properties([parameters([string(defaultValue: 'Hello', description: 'How should I greet the world?', name: 'Greeting')])])
	Handling Failures -
		Declarative Pipeline supports robust failure handling by default via its post section which allows declaring a number of different "post conditions" such as: always, unstable, success, failure, and changed
			stages { ... }
			post {
				always {
					junit '**/target/*.xml'
				}
				failure {
					mail to: team@example.com, subject: 'The Pipeline failed :('
				}
			}
		Scripted Pipeline however relies on Groovy’s built-in try/catch/finally semantics for handling failures during execution of the Pipeline.
			stage('Test') {
				try {
					sh 'make check'
				}
				finally {
					junit '**/target/*.xml'
				}
			}
		In the [test] example above, the sh step was modified to never return a non-zero exit code (sh 'make check || true'). This approach, while valid, means the following stages need to check currentBuild.result to know if there has been a test failure or not. An alternative way of handling this, which preserves the early-exit behavior of failures in Pipeline, while still giving junit the chance to capture test reports, is to use a series of try /finally blocks
	Using multiple agents
		pipeline {  // declarative pipeline
			agent none
			stages {
				stage('Build') {
					agent any
					steps {
						checkout scm
						sh 'make'
						stash includes: '**/target/*.jar', name: 'app'  // The stash step allows capturing files matching an inclusion pattern (*/target/.jar) for reuse within the same Pipeline. Once the Pipeline has completed its execution, stashed files are deleted from the Jenkins master.
					}
				}
				stage('Test on Linux') {
					agent {
						label 'linux'
					}
					steps {
						unstash 'app'  // unstash will retrieve the named "stash" from the Jenkins master into the Pipeline’s current workspace.
						sh 'make check'
					}
					post {
						always {
							junit '**/target/*.xml'
						}
					}
				}
				stage('Test on Windows') {
					agent {
						label 'windows'
					}
					steps {
						unstash 'app'
						bat 'make check'  // The bat script allows for executing batch scripts on Windows-based platforms
					}
					post {
						always {
							junit '**/target/*.xml'
						}
					}
				}
			}
		}
		
USING DOCKER WITH PIPELINE
	Practically any tool, which can be packaged in a Docker container, can be used with ease by making only minor edits to a Jenkinsfile
		pipeline {
			agent {
				docker { image 'node:7-alpine' }
			}
			stages {
				stage('Test') {
					steps {
						sh 'node --version'
					}
				}
			}
		}
	Users can specify custom Docker Volumes to mount, which can be used for caching data on the agent between Pipeline runs. This will avoid the need to re-download dependencies for subsequent runs of the Pipeline.
		agent {
			docker {
				image 'maven:3-alpine'
				args '-v $HOME/.m2:/root/.m2'
			}
		}
	Using multiple containers
		pipeline {
			agent none
			stages {
				stage('Back-end') {
					agent {
						docker { image 'maven:3-alpine' }
					}
					steps {
						sh 'mvn --version'
					}
				}
				stage('Front-end') {
					agent {
						docker { image 'node:7-alpine' }
					}
					steps {
						sh 'node --version'
					}
				}
			}
		}
	Specifying a Docker Label
		By default, Pipeline assumes that any configured agent is capable of running Docker-based Pipelines. 
		Pipeline provides a global option in the Manage Jenkins page, and on the Folder level, for specifying which agents (by Label) to use for running Docker-based Pipelines.
		
PIPELINE DEVELOPMENT TOOLS
	Snippet Generator
	Blue Ocean Pipeline Editor - The editor offers a structural view of all the stages, parallel branches, and steps in a Pipeline. The editor validates Pipeline changes as they are made, eliminating many errors before they are even committed. Behind the scenes it still generates Declarative Pipeline code.
	Command-line Pipeline Linter - Jenkins can validate, or "lint", a Declarative Pipeline from the command line before actually running it. Linting can be done via the CLI with SSH(recommended) or  HTTP POST using curl
		# ssh (Jenkins CLI)
		# JENKINS_SSHD_PORT=[sshd port on master]
		# JENKINS_HOSTNAME=[Jenkins master hostname]
		ssh -p $JENKINS_SSHD_PORT $JENKINS_HOSTNAME declarative-linter < Jenkinsfile
		
"REPLAY" PIPELINE RUNS WITH MODIFICATIONS -  allows for quick modifications and execution of an existing Pipeline without changing the Pipeline configuration or creating a new commit.
	Step -
		Step 1. Select a previously completed run in the build history.	
		Step 2. Click "Replay" in the left menu
		Step 3. Make modifications to the script and click "Run"
	Once you are satisfied with the changes, you can use Replay to view them again, copy them back to your Pipeline job or Jenkinsfile, and then commit them using your usual engineering processes.

JENKINS CLI
	The command line interface can be accessed over SSH or with the Jenkins CLI client, a .jar file distributed with Jenkins.
	In a new Jenkins installation, the SSH service is disabled by default. Administrators may choose to set a specific port or ask Jenkins to pick a random port in the Configure Global Security page
	In order to add an SSH public key for the appropriate user, navigate to JENKINS_URL/user/USERNAME/configure and paste an SSH public key into the appropriate text area.
	ssh -l <USERNAME> -p <PORT> localhost help - Jenkins has a number of built-in CLI commands which can be found in every Jenkins environment, such as build or list-jobs. Plugins may also provide CLI commands; in order to determine the full list of commands available in a given Jenkins environment, execute the CLI help command
	ssh -l <USERNAME> -p <PORT> localhost help build - One of the most common and useful CLI commands is build, which allows the user to trigger any job or Pipeline for which they have permission.
	ssh -l <USERNAME> -p <PORT> localhost help console - Similarly useful is the console command, which retrieves the console output for the specified build or Pipeline run. When no build number is provided, the console command will output the last completed build’s console output.
	ssh -l <USERNAME> -p <PORT> localhost help who-am-i - It is helpful for listing the current user’s credentials and permissions available to the user. This can be useful when debugging the absence of CLI commands due to the lack of certain permissions
	Using the CLI client -
		The CLI client can be downloaded directly from a Jenkins master at JENKINS_URL/jnlpJars/jenkins-cli.jar
		Syntax - java -jar jenkins-cli.jar [-s JENKINS_URL] -ssh -user <USERNAME> <command>
		
UNIT TESTING
	Provides a host of plugins for unit testing of other technologies such as MS Test for .net unit testing.
	Java UT -
		Step 1: Open the dashboard, choose an existing project and click configure.
		Step 2: Browse towards add a build step and invoke Ant.
		Step 3: Click on advanced.
		Step 4: Enter the location of build.xml in the build file section.
		Step 5: Click the Add post-build option and click on Publish Junit test result report.
		Step 6: Ensure the report is in the folder of the project workspace. The “*.xml” basically tells Jenkins to pick up the result xml files which are produced by running of the Junit test cases. Click Save after done.
		Step 7: Click on build and check logs to see if it is successful or not.
			
AUTOMATED TESTING
	Selenium - 
		Step 1: go to plugins and choose selenium plugins and click to install.
		Step 2: go to configure system and select on selenium jar and save
		Step 3: Go to dashboard and select the config option for the project at hand
		Step 4: Click on add build step and choose Selenium HQ html Suite Run
		Step 5: Add the required details and click on save, execute and build. The test is executed, and a report is built.
		
NOTIFICATIONS
	Jenkins comes with a feature to add email notifications to the build project
	Go-to Manage Jenkins → Configure System. In the email notification space enter the require STMP server and use email suffixes.
	Configure the recipients so that they would receive notification about broken or unstable builds
	Notification plugins such as Tikal Knowledge allows job status notification for JSON and XML formats.
	
CODE ANALYSIS
	They provide utilities for static code analysis. Some tools are CheckStyle, FindBugs, PMD etc.
	Provides details like - Total warning in a job, Showing of new and fixed warning of a build, Trend reports showing warnings per build, Detailed reports of found warnings.
	
AUTOMATED DEPLOYMENT
	There are plugins available to transfer build files to the server. E.g., deploy to container plugin. Head to the manage plugins and install the respective plugins.
	It takes the war ear file and deploys that to the running remote application build.
	Go-to build and configure and click on ‘deploy to war/ear to container’.
	In the war container section save details about the destination server and click save.
	
CONFIGURATION - Jenkins Dashboard -> Manage Jenkins -> Configure System
	https://www.tutorialspoint.com/jenkins/jenkins_configuration.htm
	
https://jenkins.io/doc/tutorials - do handson on google cloud























	
	
	
	
	
	
	
	
	
	
